\documentclass[a4paper]{article}

%% Language and font encodings
% \usepackage[english]{babel}
% \usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{graphicx}
\graphicspath {{images/}}

\title{CS698 - Winter 2017 - Assignment 2}
\author{Vineet John (v2john@uwaterloo.ca)}
\date{}


\begin{document}
\maketitle

\renewcommand\thesubsection{\alph{subsection}}

\section{Classification Algorithms}

\subsection{Mixture of Gaussians}
The cross-validation accuracy for each run is as reporting in below table.\\
The average accuracy is \textbf{0.8677}

\begin{center} 
	\begin{tabular}{ |c|c| } 
		\hline
		\textbf{Cross-validation Run} & \textbf{Accuracy} \\
		\hline
		\hline
		Set 1  & 0.883 \\
		\hline
		Set 2  & 0.847 \\
		\hline
		Set 3  & 0.856 \\
		\hline
		Set 4  & 0.91 \\
		\hline
		Set 5  & 0.865 \\
		\hline
		Set 6  & 0.892 \\
		\hline
		Set 7  & 0.838 \\
		\hline
		Set 8  & 0.892 \\
		\hline
		Set 9  & 0.82 \\
		\hline
		Set 10 & 0.874 \\
		\hline
	\end{tabular}
\end{center}
The accuracy while training and evaluating on the complete dataset is \textbf{0.889}
\\\\
\textbf{Parameters}:\\\\
$w =
\begin{tabular}{  c c c c c c  } 
	[-0.00039919 &  0.01608376 &  0.03035347 &  0.01290756 &  0.05312515 &  0.15887134 \\
	  0.02267963 &  0.03617127 &  0.08186617 & -0.02446763 &  0.11650799 &  0.0121413 \\
	  0.02111923 &  0.15654718 &  0.0109459  & -0.0506001  &  0.07229666 &  0.06398694 \\
	  0.00981228 & -0.0201207  & -0.01176678 & -0.05647826 & -0.03382154 &  0.02534816 \\
	  0.05242411 &  0.01178864 & -0.02082784 &  0.01802898 &  0.08832164 & -0.00688474 \\
	 -0.06683389 &  0.00220141 &  0.07158928 & -0.00998629 & -0.06456113 & -0.04018647 \\
	 -0.03329252 & -0.08199461 & -0.03852807 & -0.04455228 & -0.0420453  & -0.00382048 \\
	 -0.21711455 & -0.08211564 & -0.00247919 &  0.02724546 &  0.02489109 & -0.04608706 \\
	  0.03292018 & -0.09936085 & -0.07256317 & -0.05318881 &  0.06202186 & -0.03173325 \\
	 -0.07233379 &  0.00984539 & -0.02589944 & -0.07307696 &  0.09056223 &  0.05856089 \\
	 -0.01847382 & -0.04885932 &  0.00456147 &  0.01576207] & & \\
\end{tabular}$
\\\\
$w_0 = 0.105720724448$

\newpage

\subsection{Logistic Regression}

\newpage

\section{Linear Separability}

\subsection{Threshold perceptron - Activation function encoding}
\begin{figure*}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{images/activation_functions.png}
    \caption{Activation Function Weights}
    \label{fig_activation_function_weights}
\end{figure*}

\newpage

\subsection{Logistic Regression Experiment - Linear Separability}

\end{document}
